\documentclass[thesis.tex]{subfiles}

\begin{document}


\chapter{Results and Analysis}
\label{chap:results-and-analysis}

In this chapter we analyze SLHS by proving that the \emph{run} function terminates for
all valid input Subjective Logic expressions, analyze the complexity of a representative subset of the Subjective Logic operators,
discuss how Haskell's strong type system and its support for monads has affected the
design of SLHS, and finally we demonstrate the power of SLHS by showcasing some
example computations and discuss how the library fits into the
\emph{Unified Data Management and Decision Support System (UDMDSS)} \cite{kent2010application, kent2010towards}.


\section{Proof of Termination}
\label{sec:termination}

In this section we perform a termination analysis of the \emph{run} function. The
run function takes in a Subjective Logic expression and an initial state, and returns
either the computed value or an error message. We prove that run terminates for valid
Subjective Logic expressions of arbitrary length.

Our strategy for proving termination is as follows: we utilize a function $|\cdot|$ that
maps each Subjective Logic expression $e$ to a natural number. We let $|e|$
denote the number of sub-expressions contained in
$e$, including $e$ itself. As \emph{run} recursively computes the values of the
sub-expressions, we will show that the value of $|e|$ decreases at each step, concluding
when $|e|$ is 1, when \emph{run} simply returns the final value. Therefore we can conclude
that \emph{run} terminates
because the set of naturals, along with the $<$ relation, is \emph{well-founded}. That is there
cannot exist infinitely descending chains \cite{moschovakis2006notes}.

\begin{lemma}
  The \emph{return} function introduces a new sub-expression.
\end{lemma}

\begin{proof}
  The function \emph{return} in Haskell has the following signature:

  \begin{spec}
    return :: Monad m => a -> m a
  \end{spec}

  That is, for any monad m, for every object $x$ of type $a$, \emph{return x} constructs
  an object of type \emph{m a}. Since \emph{SLExpr} is a monad, \emph{return} constructs
  a new subjective logic expression containing a single value. We will use this result to
  assist us in showing that the \emph{run} function's measure decreases at every step.
\end{proof}






\begin{theorem}
  For every subjective logic expression $e = e_1 \cdot e_2 \cdot \dots \cdot e_k$, where $\cdot$
  can be any binary subjective logic operator, the computation \emph{run e} terminates.
\end{theorem}

\begin{proof}
  By induction on the length of $e$. If we can show that
  $|run\,e_1 \cdot \dots \cdot e_k| < |e_1 \cdot \dots \cdot e_k \cdot e_k|$ for all $k \geq 0$, then
  \emph{run} terminates.

  Base Case $e = e_1$: In this case, $|e| = 1$, and since \emph{run} simply applies the initial
  state to the function contained within $e$ without adding any new objects of type \emph{SLExpr},
  in other words $|run\,e| = 0$, \emph{run e} terminates.

  Inductive Hypothesis: Assume \emph{run} terminates for the expression $e = e_1 \cdot e_2 \cdot \dots \cdot e_k$.
  Given the expression $e' = e \cdot e_{k+1}$, we must prove that $|run\,e'| < |e'|$.

  Inductive Proof: Since we are adding exactly one new sub-expression to $e$ to form $e'$,
  $|e'| = |e| + 1$. Now, all binary operators of SLHS essentially have the same form:

  \begin{spec}
    op e1 e2 = e1 >>= \e -> e2 >>= \e' -> return (combine e e')
  \end{spec}

  That is, we unpack each expression and then combine them together in some meaningful way to produce
  a new value of type \emph{SLExpr}. Let us analyze the first monadic bind operator.

  \begin{spec}
    e1 >>= \e -> e2 >>= \e' -> return (combine e e')
  \end{spec}

  first calls \emph{run} on $e1$, then passes the result of that computation to the lambda function

  \begin{spec}
    \e -> e2 >>= \e' -> return (combine e e')
  \end{spec}

  and calls \emph{run} on the result. Inside the nested lambda expression, the second monadic bind operator
  calls \emph{run} on $e2$, passing the result into the lambda expression

  \begin{spec}
    \e' -> return (combine e e')
  \end{spec}

  and then invoking \emph{run} on \emph{that} result. The innermost invocation of \emph{run} makes a call
  to \emph{return}, thus inserting a new object of type \emph{SLExpr}. Combined together with the two
  invocations of \emph{run} on the input expressions, we have

  \begin{equation*}
  \begin{split}
    |run\,e \cdot e_{k + 1}|& = |run\,e| + |run\,e_{k+1}| + |return\,x| \\
                     & = |run\,e| + 0 + 1 \\
                     & < |e| + 1 \\
                     & = |e \cdot e_{k+1}|
  \end{split}
  \end{equation*}

\end{proof}



%
% Make sure the mention binomial opinions are O(1).
%


\section{Analysis of Complexity}
\label{sec:complexity}

In this section we analyze the time complexity of a representative subset of the SLHS operators. We
analyze the complexity of belief constraining to demonstrate how computationally expensive it is to
work with hyper opinions, which are defined over the reduced power set of the frame of discernment.
Next we analyze the complexity of belief fission, an operator defined over multinomial opinions.
Lastly, we analyze the complexity of multinomial multiplication.

We do not claim that the implementations of the operators are optimal. In fact, our implementations
are very sensitive to our choice of data structure for representing belief assignments: the red-black
tree. Iterating through the entire belief mass assignment takes $O (n)$ time, but finding an individual
element takes $O (\log n)$ time. Alternative representations may possibly be more efficient, and we leave
that for future work.

It is also worthy to note that every operator that is implemented solely for binomial opinions has
complexity $O(1)$ with respect to the size of the frame of discernment. Recall that binomial opinions
are either defined as opinions over a frame of cardinality 2, or are defined over binary partitions of
frames. In either case, each equation involves calculating new values for $b$, $d$, $u$, and $a$ without
any regard to the actual size of the frame. Therefore each calculation on binomial opinions will be
carried out in a constant amount of time.

\begin{theorem}
  Belief constraining has time complexity $O ((2^n - 2)^3 \log (2^n - 2))$,
  where $n$ is the cardinality of the frame of discernment.
\end{theorem}

\begin{proof}
  Since belief constraining is defined over hyper opinions, let $m = 2^n - 2$ be the cardinality
  of the reduced power set of the frame. Computing the \emph{conflict} requires finding all elements of
  the power set that share overlap and adding together their assigned belief masses. This operation
  takes $O (m^2)$ time for the iteration, and $O (\log m)$ for looking up the belief masses. Therefore
  conflict takes $O (m^2 \log m)$ time.

  Computing the new belief mass requires computing the \emph{Harmony} for every element of the power set.
  Computing the harmony takes $O (m^2)$ time per element, resulting in a time complexity of $O (m^3 \log m)$
  for computing the new belief mass.

  Computing the uncertainty requires computing the conflict, which we have already computed as a part of
  the new belief mass.

  Atomicity requires iterating over the entire reduced power set, and thus requires $O (m \log m)$ time.

  Therefore the total time complexity for belief constraining is
  $O (m^3 \log m + m^2 \log m + m \log m) = O (m^3 \log m) = O ((2^n - 2)^3 \log (2^n - 2))$.
\end{proof}

\begin{theorem}
  Multinomial fission has time complexity $O (n)$, where $n$ is the cardinality of the frame of discernment.
\end{theorem}

\begin{proof}
  Computing the normalizing constant takes $O (n)$ time. Since computing the new beliefs and uncertainties
  requires iterating over each element of the frame of discernment, each takes $O (n)$ time. Therefore, the
  time complexity for fission is $O (n)$.
\end{proof}

\begin{theorem}
  Multinomial multiplication has time complexity $O (m \log m \times n \log n)$.
\end{theorem}

\begin{proof}
  The \emph{expect x y} function takes $O (\log m + \log n)$ time, since it needs to perform
  look-ups on each frame. Computing the uncertainty takes $O (m \log m \times n \log n)$ time,
  computing the new atomicity takes $O (m \log m \times n \log n)$ time, and computing the new
  belief also takes $O (m \log m \times n \log n)$ time. Therefore the entire time complexity is
  $O (m \log m \times n \log n)$.
\end{proof}




%
% Maybe mention other operators that are similar to the ones analyzed.
%





\section{The Use of Haskell's Type System}
\label{sec:types}

In this section we discuss how SLHS leverages Haskell's type system to catch many errors
at compile time, instead of at run time. With SLHS we have taken the motto of \emph{catch what we
can at compile time, report what we must at run time}. There are certain properties of well-formed
Subjective Logic expressions that can only be caught at run time, such as

\begin{itemize}
  \item the inputs to the binomial addition operator are subsets of the same frame
    of discernment.
  \item the inputs to the transitive discounting operator have different belief
    owners.
  \item the subset relation required for binomial subtraction is satisfied.
\end{itemize}

For other issues however, such as restricting addition to work on binomial opinions only, we can
leverage Haskell's strong typing to stop those invalid expressions from even compiling.

Consider the type signature for the binomial addition operator:

\begin{spec}
(+!) :: (ToBinomial op1, ToBinomial op2, Eq h, Eq b, Ord b)
        => SLExpr h a (op1 h b)
        -> SLExpr h a (op2 h b)
        -> SLExpr h a (Binomial h b)
\end{spec}

What this tells us is that addition takes in two parameters, \emph{op1} and \emph{op2}, each wrapped in
the \emph{SLExpr} monad. These two opinion types must be convertible to binomials, as they must belong to
the type class \emph{ToBinomial}. This signature also tells us that the elements of the frame must be of
the same type. Therefore, if any one of the opinions is constructed over the cartesian product of two frames,
then both opinions must be constructed over the cartesian product of two frames. Checking whether the two
frames are in fact the same must be deferred until run time, however.

\section{The Use of Monads}
\label{sec:monads}

In this section we describe the role that monads have played in the design of SLHS. As mentioned
previously, the \emph{SLExpr} type, which is the type used to represent Subjective Logic expressions within SLHS, is a function from
a world state, \emph{SLState}, to some output value. \emph{SLExpr} forms a monad, and thus we are
able to use all of Haskell's built-in support for monads when writing computations involving
objects of type \emph{SLExpr}. In particular, \emph{SLExpr} is a special kind of \emph{state monad},
where the state carried through the computation is an \emph{SLState} object.

Because they are monads, objects of type \emph{SLExpr} can be glued together using the various
operators and functions in the Haskell standard library. One function that we use quite frequently
in the implementation of SLHS is the \emph{liftM} function, which takes an ordinary function from
some type $a$ to type $b$, and converts it into a function from type $M\,a$ to $M\,b$, where $M$ is
any monad. This allows us to use functions such as \emph{toBinomial} directly on objects of type
\emph{SLExpr} without having to unwrap them first.

Another benefit of \emph{SLExpr} being a monad is that we are able to use Haskell's \emph{do-notation}
in order to simplify our code. Do-notation allows us to write code of the form

\begin{spec}
z = mx >>= \x -> my >>= \y -> return (x + y)
\end{spec}

where each and every invocation of the bind operator must be explicitly written, as

\begin{spec}
z = do x <- mx
       y <- my
       return (x + y)
\end{spec}

This syntactic sugar not only allows the implementation of SLHS to be written more
concisely in many cases, but it also extends to users of SLHS as well. Complicated
Subjective Logic expressions can be broken down into smaller pieces, and then glued
together in a style that looks very imperative:

\begin{spec}
expr = do e1 <- getMultinomial ``Alice'' 0
          e2 <- getMultinomial ``Bob'' 0
          e3 <- e1 `times` e2
          e4 <- e3 `cFuse` (getHyper ``Clark'' 0)
          return e4
\end{spec}

which may help programmers who are more accustomed to writing programs in more mainstream
structural languages such as \emph{Python} \cite{van2003python} or \emph{Ruby} \cite{matsumoto2002ruby}.
In the next section we demonstrate how
problems involving Subjective Logic can be modeled and executed using SLHS.




\section{Example Computations}
\label{sec:examples}

In this section we demonstrate the use of SLHS on a selection of examples provided in the
Subjective Logic literature.

\subfile{./SLHS/examples/Ex1.lhs}
\subfile{./SLHS/examples/Ex2.lhs}



\section{Utilization Within UDMDSS}

As mentioned in Section \ref{sec:dss}, we have participated in a team effort to design the
Unified Data Management and Decision Support System (UDMDSS)
as a part of our ongoing research into the development of decision support systems for
the management and analysis of population research surveys \cite{kent2010towards, kent2011design, kobti2011towards}.
SLHS was designed to aide in the
development of automated reasoning systems that utilized Subjective Logic, and though it has
not been integrated yet, we expect that SLHS will find a place in the heart of the UDMDSS
system. Further development on UDMDSS will see SLHS put to the test of analyzing real health care
data using the tools of Subjective Logic.




\section{Summary}

In this chapter we presented a termination analysis for the \emph{run} function of SLHS, proving
that it terminates for all valid expressions. We then provided a complexity analysis for a selection
of Subjective Logic operators. We also discussed how Haskell's type system is leveraged in SLHS
to catch problems with Subjective Logic expressions at compile time, and how the use of monads facilitated a sound design.
We also provided some example calculations with SLHS, and we discussed its position within the larger UDMDSS system.
In the next chapter we conclude this thesis and discuss areas in which we feel SLHS can be improved.



\end{document}
